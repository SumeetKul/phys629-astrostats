{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4adbb7-6481-493e-ae1f-0c013e777f71",
   "metadata": {},
   "source": [
    "# Statistical Inference\n",
    "\n",
    "## Frequentist vs. Bayesian Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88a63d-698c-484c-b183-cff7e07eb2b4",
   "metadata": {},
   "source": [
    "## Statistical Inference <a class=\"anchor\" id=\"one\"></a>\n",
    "\n",
    "Statistical *inference* is about drawing conclusions from data, specifically determining the properties of a population by data sampling.\n",
    "\n",
    "Three examples of inference are:\n",
    "1. What is the best estimate for a model parameter?\n",
    "\n",
    "If we measure some data recorded by/as a random variable $d = \\{x_i\\}$, we can have a model (M) that describes $\\{x_i\\}$ using a set of parameters $\\vec{\\theta}$. There will be a true set of values for these parameters in nature $\\vec{\\theta}_{0}$, but our parameter estimation returns our best estimates of this based on the measurements we've made. Ideally, if our experiment is precise, if the noise is low and the number of measurements is large, we will be closer to this true value. \n",
    "   \n",
    "2. How confident are we about our result?\n",
    "3. Are the data consistent with a particular model/hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573608d-6a3c-45bd-aaff-7f19e8636ae5",
   "metadata": {},
   "source": [
    "### Some Terminology\n",
    "\n",
    "* We typically study the properties of some ***population*** by measuring ***samples*** from that population. The population doesn't have to refer to different objects. E.g., we may be (re)measuring the position of an object at rest; the population is the distribution of (an infinite number of) measurements smeared by the uncertainty, and the sample are the measurement we've actually taken.\n",
    "\n",
    "\n",
    "* A ***statistic*** is any function of the sample. For example, the sample mean is a statistic. But also, \"the value of the first measurement\" is also a statistic. Don't stress too much about how to make a statistic; it's just a way of summarizing data in a way that helps reveal the presence of a signal. We will meet ways of finding the optimal statistic for a given scenario.\n",
    "\n",
    "\n",
    "* To conclude something about the population from the sample, we develop ***estimators***. An estimator is a statistic, a rule for calculating an estimate of a given quantity based on observed data.\n",
    "\n",
    "\n",
    "* There are ***point*** and ***interval estimators***. The point estimators yield single-valued results (example: the position of an object), while with an interval estimator, the result would be a range of plausible values (example: confidence interval for the position of an object).\n",
    "\n",
    "\n",
    "* Measurements have **uncertainties** (not errors) and we need to account for these (sometimes they are unknown). Data are not variables but fixed values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b6850-5f66-4de6-b829-230860a652c8",
   "metadata": {},
   "source": [
    "### Frequentist vs. Bayesian Inference\n",
    "\n",
    "There are two major statistical paradigms that address the statistical inference questions: \n",
    "- the **classical**, or **frequentist** paradigm,\n",
    "- the **Bayesian** paradigm.\n",
    "\n",
    "While most of statistics and machine learning is based on the classical paradigm, Bayesian techniques are being embraced by the statistical and scientific communities at an ever-increasing pace...especially in astrophysics.\n",
    "\n",
    "#### Key differences\n",
    "- **Definition of probabilities**:\n",
    "    - In ***frequentist inference***, probabilities describe the ***relative frequency of events*** over repeated experimental trials. \n",
    "    - In ***Bayesian infernece***, probabilities instead quantify our ***subjective belief about experimental outcomes, model parameters, or even models themselves***. \n",
    "    \n",
    "    \n",
    "- **Quantifying uncertainty**:\n",
    "    - In ***frequentist inference*** we have ***confidence levels*** that describe the distribution of the measured parameter from the data around the true value.\n",
    "    - In ***Bayesian inference*** we have ***credible regions*** derived from posterior probabilitiy distributions (we'll meet these later). These encode our \"***belief spread***\" in model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee75e05-73d0-4188-abaa-2277f281a72c",
   "metadata": {},
   "source": [
    "For an in-depth and practical discussion: http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5f7a4-82c4-44e0-8067-6daee03632e6",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation (MLE) <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "Let's talk about maximum likelihood estimation ($\\S 4.2$ in the textbook), which is relevant to both Bayesian and Frequentist approaches.\n",
    "\n",
    "### Maximum Likelihood Approach\n",
    "\n",
    "Maximum likelihood estimation follows this blueprint:\n",
    "\n",
    "1. **Hypothesis**: Formulate a model, a *hypothesis*, about how the data are generated. For example, the data are a measurement of some quantity with Gaussian random uncertainties (i.e., each measurement is equal to the true value, plus a deviation randomly drawn from the normal distribution). Models are typically described using a set of model parameters $\\boldsymbol{\\theta}$, and written as $\\boldsymbol{M}(\\boldsymbol{\\theta})$.\n",
    "\n",
    "\n",
    "2. **Maximum Likelihood Estimation**: Search for the \"best\" model parameters $\\boldsymbol{\\theta}$ which maximize the ***likelihood*** $L(\\boldsymbol{\\theta}) \\equiv p(D|M)$. This search yields the MLE *point estimates*, $\\boldsymbol{\\theta^0}$.\n",
    "\n",
    "\n",
    "3. **Quantifying Estimate Uncertainty**: Determine the confidence region for model parameters, $\\boldsymbol{\\theta^0}$. Such a confidence estimate can be obtained analytically (possibly with some approximations), but can also be done numerically for arbitrary models using general frequentist techniques, such as bootstrap, jackknife, and cross-validation (we'll come to these later).\n",
    "\n",
    "\n",
    "4. **Hypothesis Testing**: Perform hypothesis tests as needed to make other conclusions about models and point estimates. Possibly GOTO #1.\n",
    "\n",
    "\n",
    "\n",
    "### Example: Measuring the Position of a Quasar\n",
    "\n",
    "Let's assume we wish to estimate the position $x$ of a quasar from a series of individual astrometric measurements.\n",
    "\n",
    "1. We adopt a model where the observed quasar does not move, and has individual measurement uncertainties \n",
    "2. We derive the expression for the likelihood of there being a quasar at position $x_0$ that gives rise to our individual measurements. We find the value of $\\hat x_0$ for which our observations are maximally likely.\n",
    "3. We determine the uncertainties (confidence intervals) on our measurement.\n",
    "4. We test whether what we've observed is consistent with our adopted model. For example, is it possible that the quasar was really a misidentified star with measurable proper motion?\n",
    "\n",
    "Note: in the text to come, we will use $\\mu$ instead of $x_0$ to denote the true position of the quasar. This is to avoid potential confusion with the first (or zeroth) measurement of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96a978-926b-44ff-a2eb-5ff28d4a5b55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:phys629] *",
   "language": "python",
   "name": "conda-env-phys629-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
